\section{Circuit-independent pairing-based SNARKs}
\noindent Homogeneous computation aside, circuit-specific pairing-based methods have a couple of noteworthy shortcomings. The first of these, as noted by Groth, is that there is no way of ensuring the deployers of the SNARK in question have disposed of the secret randomness used to generate the trusted setup. The second and more important issue is a lack of flexibility due to the use of computation-dependent (non-universal) preprocessing. Consider the groth16 trusted setup for instance: 
\begin{align}
\sigma = \Big( 
    &[\alpha]_1, [\beta]_1, [\gamma]_1, [\delta]_1, \\
    &\{[x^i]_1\}_{i \in [0, n-1]}, \\
    &\{[\gamma^{-1}(\beta u_i(x) + \alpha v_i(x) + w_i(x))]_1\}_{i \in [0, \ell]}, \\
    &\{[\delta^{-1}(\beta u_i(x) + \alpha v_i(x) + w_i(x))]_1\}_{i \in [\ell+1, m]}, \\
    &\{[\delta^{-1} x^i t(x)]_1\}_{i \in [0, \deg(h)]}, \\
    &[\beta]_2, [\gamma]_2, [\delta]_2, \{[x^i]_2\}_{i \in [0, n-1]}
\Big)
\end{align}

\noindent As is the case with other discussed methods, the contributions of the $i$-th witness component to gate $g$ are ``hardcoded'' in the $u_i(x), v_i(x), w_i(x)$ (not the component's value, but its index). Thus if the computation changes, the setup terms encoding the hidden combinations of the $v_i(x), w_i(x), y_i(x), \text{etc.}$ must be regenerated. A natural question arises: why not just update the setup somehow if the computation structure changes? This is not possible for two reasons, either of which is sufficient to deter updatability. The first is that, as mentioned the hidden $u_i(x), v_i(x), w_i(x)$ are interpolated from relationships between witness values (secret) and the gates they feed into. Adding a new gate and its associated wire connections would require adding a new data point to each of these polynomials. Thus, one would have to re-interpolate all of them which is not possible without violating cryptographic assumptions (since they are encrypted). The other reason concerns the setup's combination of these hidden polynomial terms, such as the $[\beta u_i(x) + \alpha v_i(x) + w_i(x)]_1$. Groth showed these setup terms could be used to extract the the constituent monomials and ultimately break soundness if the setup allowed updates. These observations suggest that the conception of a QAP-based updatable SNARK is unlikely, and that different approaches are necessary.\\

\noindent To address these shortcomings, Groth produced a multivariate scheme that encoded QAP elements differently and achieved constant proof size and verification complexity. Although this scheme involved a linear-time procedure by which a linear-size circuit-specific setup could be produced as needed, true universality required quadratically many terms w.r.t circuit size. Furthermore, SRS updates take a quadratic number of group exponentiations and update verification a linear number of pairing operations. For circuits with millions of gates this is impractical. Nonetheless, this hints that a SNARK with linear-size universal \& updatable setup could be attainable if the setup terms are univariate (and monomial).\\

\noindent Maller et al. achieved a linear with Sonic, which draws inspiration from to build a SNARK reducing checking computation to checking evaluations of Laurent polynomials. Unlike with previous work, these polynomials can be represented in the (updatable) setup using univariate terms, requiring linear setup space. Though a breakthrough in its own right, Sonic suffers from very large constants in proof construction complexity despite being asymptotically quasilinear. A likely cause is the attempt to accommodate for $n$-fan-in circuits whose gates can accept arbitrarily many inputs. This means each intermediate gate would have an arbitrary amount of associated copy constraints, which would deny any attempt to condense or collapse the permutation argument based on structural assumptions. Gabizon et al. instead used a simpler arithmetization combined with structural assumptions about the number of inputs each circuit gate receives (2 inputs per gate). Here, each gate constraint can express any gate, and their permutation argument only requires a constant number of permutation check per gate due to the 2-fan-in assumption. Combining these traits with randomized interaction from the verifier yields a polynomial divisibility relation involving a random linear combination of the polynomials encoding the gate relations and copy constraints. This can be checked using univariate KZG commitment scheme, marking the use of pairing-based cryptography. The resulting scheme is known as ``PlonK'', where the ``L'' refers to ``Lagrange bases'' consisting of sparsely represented Lagrange polynomials defined over the roots of unity. These polynomials are used in the interpolation and aggregation of the various polynomials involved in proof construction.\\

\noindent The combination of flexibility, intuitive arithmetization, and better efficiency has made PlonK a catalyst for advancement.
