\section{Circuit-specific pairing-based SNARKs}
\noindent The seminal PCP theorem results \cite{pcpthm1, pcpthm2} yielded a powerful characterization of NP as a set of languages with polynomial-time PCP verifiers only needing to view a constant number of proof bits \textit{regardless of proof size}. However, early work on pairing-based SNARKs by Gennaro et al. \cite{snarknopcp} was actually motivated by the possibility of succinct arguments of knowledge using a representation \textit{more suitable than PCPs} for integration with cryptographic primitives. Several other works [\textbf{WHICH ONES}] came close to meeting this end but could not attain sublinear proof size.\\

\noindent To this end, Gennaro et al. \cite{snarknopcp} coined quadratic span programs (QSP) and quadratic arithmetic programs (QAP). These representations of NP allow one to reduce checking a computation to checking a multiplicative relationship between two polynomials in a way that ``computes'' the circuit representing the computation. Although the QSP construction is noteworthy, we limit discussion to their QAP-related construction due to the clearer connection to arithmetic circuits and downstream polynomial checking. We recall the strong QAP form here:
\begin{align}
\underbrace{\left(\sum_{j=1}^n a_i v_i(x)\right)}_{\text{left inputs}} \cdot \underbrace{\left(\sum_{j=1}^n b_i w_i(x)\right)}_{\text{right inputs}} - \underbrace{\left(\sum_{j=1}^n c_i y_i(x)\right)}_{\text{outputs}} = h(x) t(x) \equiv 0 \mod t(x)
\end{align}

\noindent This idea leverages an additively homomorphic encoding $E$ -- namely, a one-to-one, function for which addition operations are preserved in the output space, and inversion is difficult. Given an instance of arithmetic circuit satisfiability one is trying to prove/verify, $E$ serves to compile the corresponding QSP/QAP instance checking polynomial divisibility (by $t(x)$) into a proof containing just 9 group elements (non-ZK). We detail the non-zero-knowledge version here for clarity, denoting $E(x)$ by $[x]$. The prover $\mathcal{P}$ computes the quotient polynomial $h(x)$ and sends
\begin{align}
    \pi = \Big(&[v_{mid}(s)], [w(s)], [y(s)], [h(s)], \\ 
    &[\alpha v_{mid}(s)], [\alpha w(s)], [\alpha y(s)], [\alpha h(s)], \\ 
    &[\beta_v v_{mid}(s) + \beta_w w(s) + \beta_y y(s)]\Big)
\end{align}

where $\alpha, s, \beta_v, \beta_w, \beta_y \in \mathbb{F}_p, $ are secret random preprocessing elements; $v_{mid}(s), w(s), y(s)$ are the witness-weighted combinations of the wiring polynomials in the QAP; and $h(s)$ is the evaluation of the quotient polynomial an honest prover would know. In particular, $v_{mid}(x) = \sum_{k \in \mathcal{I}_{mid}} a_k v_k(x)$ where $\mathcal{I}_{mid}$ are the indices corresponding to private circuit inputs. $w(x), y(x)$ are definedn similarly, but over all $k \in \{0 \dots m\}$. The verifier in turn checks 5 equations using the additive properties of $E$. In particular, the verifier receives the following proof $\pi'$ \textit{which it does not yet know is valid}, hence the new notation of elements reminiscent of those in $\pi$:
\begin{align}
\pi' = (\pi_{v_{mid}}, \pi_{w}, \pi_{y}, \pi_{h}, \pi_{v'_{mid}}, \pi_{w'}, \pi_{y'}, \pi_{h'}, \pi_{z'})
\end{align}

\noindent $\mathcal{V}$ then checks 6 pairing equations involving the components of $\pi'$ (recall the pairing notation from earlier section):  
\begin{align}
&e([v_0(s) + v_{in}(s) + v_{mid}(s)]_1, [w_0(s) + w_{in}(s) + w_{mid}(s)]_2) = \\ 
&e([t(s)]_1, [h(s)]_2) \cdot e([y_0(s) + y_{in}(s) + y_{mid}(s)]_1, G_2) \\
&e([v_{mid}'(s)]_1, G_2) = e([v_{mid}(s)]_1, [\alpha]_2) \\
&e([w'(s)]_1, G_2) = e([w(s)]_1, [\alpha]_2) \\
&e([y'(s)]_1, G_2) = e([y(s)]_1, [\alpha]_2) \\
&e([h'(s)]_1, G_2) = e([h(s)]_1, [\alpha]_2) \\
&e([z'(s)]_1, [\gamma]_2) = e([\beta_v v_{mid}(s) + \beta_w w(s) + \beta_y y(s)]_1, [\gamma]_2)
\end{align}
\noindent where $v'_{mid}(s)$ is encoded in $\pi_{v'_{mid}}$, $w'(s)$ is encoded in $\pi_{w'}$, and so on. The first one checks the QAP divisibility relation. The next four equations are based on $q$-PKE where $q = 1$; they check if $\mathcal{P}$ knows the wiring polynomials used in the proof. The last equation checks that $\mathcal{P}$'s proof used wiring polynomials consistent with those agreed upon in the trusted setup. \\

\noindent GGPR uses a \textit{strong} QAP for their scheme, which uses a different set of coefficients for each sum in the QAP equation. This mandates a \textit{strengthening step} in which extra constraints between the coefficient sets are materialized, tripling prover work and preprocessing size. Parno et al. \cite{pinocchio} made the simple optimization of using a \textit{regular} QAP, which uses the same set of coefficients $a_i$ for each sum in the QAP expression, contrary to the $a_i, b_i, c_i$ seen in the strong QAP form. This change eliminated the need for the strengthening step without any noteworthy compromises, although it required modifications to proof elements and verification checks that ensure consistent use of coefficients in QAP terms. \textbf{WHAT ARE THE OPTIMIZATIONS OVER GGPR?}\\

\noindent With these two methods as a springboard, Groth \cite{groth16} used stronger security assumptions to make massive improvements in proof size, setup size, and verifier complexity. Groth still used the regular QAP representation; but unlike previous methods that compiled each polynomial evaluation into two group elements, he compiled the wiring polynomials to just one group element (ex. just $w(s)$ instead of $w(s), \alpha w(s)$). This eliminates multiple setup terms, reduced proof size to 3 group elements, and reduced verifier operations to a single pairing check using three pairings. This imaginably resulted in a massive performance increase across multiple fronts over previous methods. However, this single-element compilation prevents use of 1-PKE assumptions, so security is argued in the generic group model where, loosely speaking, adversaries cannot exploit any group specific properties. While seemingly strong, such assumptions are not necessarily uncalled for, as Gentry et al. have already shown that SNARKs for NP cannot exist without non-falsifiable assumptions to begin with \cite{nonfalsifiable}. Reduction in proof size and verifier complexity could also be regarded as "worth the security assumptions" on this front. Consequently, Groth's work (colloquially known as groth16) saw large adoption in blockchain systems verifying homogeneous computation; applications like Tornado Cash \cite{tornadocash} use this method to verify withdrawals from privacy-preserving pools without exposing source-destination address relationships; and UTXO-based privacy-preserving blockchains like Zerocash network \cite{zcash} used groth16 to prove/verify presence of unspent funds in the merkle tree inherent to the UTXO model.

% \begin{align}
% \underbrace{\left(\sum_{j=1}^n a_i v_i(x)\right)}_{\text{left inputs}} \cdot \underbrace{\left(\sum_{j=1}^n a_i w_i(x)\right)}_{\text{right inputs}} - \underbrace{\left(\sum_{j=1}^n a_i y_i(x)\right)}_{\text{outputs}} = h(x) t(x) \equiv 0 \mod t(x)
% \end{align}
% \begin{align}
% r_v, r_w, s, \alpha_v, \alpha_w, \alpha_y, \beta, \gamma &\overset{R}\leftarrow \mathbb{F} \\
% r_y &= r_v r_w \\
% g_v &= r_v G \\
% g_w &= r_w G \\
% g_y &= r_y G
% \end{align}

% \noindent The prover $\mathcal{P}$ would send 
% \begin{align}
%     \pi_2 = \Big(&[v_{mid}(s)], [w_{mid}(s)], [y_{mid}(s)], [h(s)], \\
%     [&\alpha_v v_{mid}(s)], [\alpha_w w_{mid}(s)], [\alpha_y y_{mid}(s)], \\
%     [&\beta_v v_{mid}(s) + \beta_w w_{mid}(s) + \beta_y y_{mid}(s)]\Big)
% \end{align}

% \noindent where like before, $v_{mid}(x) = \sum_{k \in \mathcal{I}_{mid}} a_k v_k(x)$ and likewise for $w_{mid}(x)$, $y_{mid}(x)$. Similar to GGPR, the verifier receives
% $$
% \textbf{THE POTENTIALLY VALID PROOF THE VERIIFER RECEIVES}
% $$
% and checks the following pairing-based equations:
% \begin{align}
% e([v_0(s) + v_{in}(s) + v_{mid}(s)]_1 \cdot [w_0(s) + w_{in}(s) + w_{mid}(s)]_1, G_2) = \\
% ([t(s)]_1, [h(s)]_2) \cdot e([y_0(s) + y_{in}(s) + y_{mid}(s)]_1, G_2) \\
% e([r_v v'_{mid}(s)], G) = e([v_{mid}(s)], [r_v \alpha]) \\
% e([r_w w'_{mid}(s)], G) = e([w_{mid}(s)], [r_w \alpha]) \\
% e([r_y y'_{mid}(s)], G) = e([y_{mid}(s)], [r_y \alpha]) \\
% e(z'(s), [\gamma]) = e([r_v v_{mid}(s) + r_w w_{mid}(s) + r_y y_{mid}(s)], [\beta \gamma])
% \end{align}
