\section{Introduction}
\noindent Loosely speaking, a succinct non-interactive argument of knowledge (SNARK) is a short, one-shot proof that one $knows$ some ``witness'' or value $w$ satisfying a statement of the form ``$x$ is in the language $L \in \text{NP}$.'' A \textit{prover} $\mathcal{P}$ would send a such a proof to a \textit{verifier} $\mathcal{V}$, which checks the proof against the statement to be proven and either accepts the proof or rejects it. Unlike traditional arguments, arguments \textit{of knowledge} require the prover to show that they know the right ``evidence'' for the statement they are trying to prove; for instance, they should not be able to mix and match valid statements and valid witnesses which are not actually related to each other. Ultimately, the proof should convince the verifier that the prover knows the witness, not just that the statement being proven is true. To accommodate for this stronger requirement, SNARKs are often defined in terms of an efficiently decidable binary relation $\mathcal{R}$ connecting statements of membership in an NP language (so-called ``NP statements'') with the correct ``supporting evidence'' (witness); this relation is then used to define the language $L$, thereby capturing all valid statements for which some corresponding evidence exists. We give this more formal definition below, in which one should assume the security parameter $\lambda$ is implicitly passed to the algorithms that do not mention it.

\begin{definition}[Succinct Non-Interactive Argument of Knowledge]\label{def:snark}
    \noindent Let $\mathcal{R} \subseteq \{0, 1\}^{*} \times \{0, 1\}^{*}$ be an NP relation (i.e., decidable in deterministic polynomial time and $|w| = \mathsf{poly}(|x|)\ \forall (x, w) \in \mathcal{R}$). Let $\lambda \in \mathbb{N}$ denote the security parameter controlling the hardness of violating cryptographic assumptions. Define the language $L_\mathcal{R} = \{x\ |\ \exists w\ \text{s.t.}\ (x, w) \in \mathcal{R}\}$. A succinct non-interactive argument of knowledge (SNARK) for $\mathcal{R}$ is a tuple of probabilistic polynomial-time algorithms $(\sf{Setup}, \sf{Prove}, \sf{Verify})$ where:
\begin{itemize}
    \item $\sf{Setup}(1^{\lambda}, \mathcal{R}) \rightarrow \sigma$ outputs a common reference string $\sigma$
    \item $\sf{Prove}(\sigma, x, w) \rightarrow \pi$ outputs a proof $\pi$
    \item $\sf{Verify}(\sigma, x, \pi) \rightarrow \{0, 1\}$ outputs accept (1) or reject (0)
\end{itemize}

\noindent and $\sf{Setup}, \sf{Prove}, \sf{Verify}$ satisfy the following properties:
\begin{itemize}
    \item \textbf{Completeness:} For all $(x, w) \in \mathcal{R}$, if $\sigma \leftarrow \sf{Setup}(1^{\lambda}, \mathcal{R})$ and $\pi \leftarrow \sf{Prove}(\sigma, x, w)$, then $\Pr[\sf{Verify}(\sigma, x, \pi) = 1] \geq 1 - \mathsf{negl}(\lambda)$.
    
    \item \textbf{Computational Knowledge Soundness:} For any PPT adversary $\mathcal{A}$, there exists a PPT extractor $\mathcal{E}$ such that:
    \begin{align*}
    \Pr\left[\begin{array}{l}
    \sigma \leftarrow \sf{Setup}(1^{\lambda}, \mathcal{R}); \\
    (x, \pi) \leftarrow \mathcal{A}(\sigma); \\
    w \leftarrow \mathcal{E}^{\mathcal{A}}(\sigma) \\
    : \sf{Verify}(\sigma, x, \pi) = 1 \land (x, w) \notin \mathcal{R}
    \end{array}\right] \leq \mathsf{negl}(\lambda)
    \end{align*}
    where $\mathcal{E}^{\mathcal{A}}$ indicates that $\mathcal{E}$ has black-box access to $\mathcal{A}$.
    
    \item \textbf{Succinctness:} For any $(x, w) \in \mathcal{R}$ where $|x| = n$:
    \begin{itemize}
     \item Prover complexity is $\mathsf{poly}(\lambda) \cdot n \cdot \mathsf{polylog}(n)$ (quasilinear in statement size)
        \item The proof size $|\pi| = \mathsf{poly}(\lambda, \log n)$ (sublinear in proof size) 
        \item Verifier complexity is $\mathsf{poly}(\lambda, \log n)$ (sublinear in statement size)
    \end{itemize}
    
    \item \textbf{Non-interactivity:} After setup, the prover sends exactly one message to the verifier.
    \item \textbf{Computational Zero-Knowledge:} There exists a PPT simulator $\mathcal{S}$ such that for any PPT adversary $\mathcal{A}$, any $(x, w) \in \mathcal{R}$, the following distributions are computationally indistinguishable:
    \begin{align*}
    \left\{ \begin{array}{l}
    (\sigma, \tau) \leftarrow \sf{Setup}(1^{\lambda}, \mathcal{R}); \\
    \pi \leftarrow \sf{Prove}(\sigma, x, w) : (\sigma, x, \pi)
    \end{array} \right\} \approx_c
    \left\{ \begin{array}{l}
    (\sigma, \tau) \leftarrow \sf{Setup}(1^{\lambda}, \mathcal{R}); \\
    \pi \leftarrow \mathcal{S}(\sigma, \tau, x) : (\sigma, x, \pi)
    \end{array} \right\}
\end{align*}
\end{itemize}
\end{definition}

\noindent For example, $L$ could be the set of satisfiable boolean circuits. Here, the statement is ``$C$ is in $L$'' where $C$ is the circuit in question, and the witness $w$ would be the satisfying assignment to $C$'s inputs. In a blockchain setting, $L$ could be the set of tuples $(P, z)$ where $P$ is an on-chain program (smart contract) and $z$ is the claimed output of running $P$ on some inputs. The witness would contain $x, y$ and potentially other information needed to verify the output of the execution path through $P$.\\

\noindent The notions of non-interactivity, computational knowledge soundness, and computational zero-knowledge in definition \ref{def:snark} warrant explanation. Firstly, an interactive proof can be turned non-interactive by using the Fiat-Shamir transform, in which the challenges normally issued by the verifier are computed by the prover as the hash of all public values and messages between the two of them up to the current point. In the previous blockchain-related example, suppose the prover sends a commitment $c_1$ to some proof elements. The verifier's first challenge would be computed by the prover as $\alpha = h(P || z || c_1)$ for instance. Since $\alpha$ would be considered a message traditionally sent by the verifier, the next challenge would be computed as $h(P || z || c_1 || \alpha || r_1)$, where $r_1$ is the prover's response to the challenge $\alpha$. Since the verifier knows the public messages used to generate the sequences of hashes, it can verify that the prover generated the challenges correctly. One can think of this as follows: instead of the verifier sending a ``question`` to ask the prover, receiving an answer, and repeating this cycle, the prover deterministically picks all the questions the verifier should ask, answers them, then puts the questions and their answers in a single ``report'' and sends it to the verifier. The verifier then verifies that the right questions were picked, and that the answers to those questions are correct. This scheme has been proven to preserve completeness and soundness properties in the Random Oracle model \cite{rom}, where all parties involved have access to a truly random function they can query as an oracle (for hashing, among other things).\\

\noindent In this non-interactive setting and others, ``Computational'' implies the adversary cannot do anything that takes asymptotically more than polynomial time. Constrast this with ``statistical`` knowledge soundness, which would imply that even a computationally unbounded adversary would have at most a small probability of breaking the aforementioned knowledge soundness requirements. The same logic applies to the computational zero-knowledge property, which says it is intractable to distinguish between the distributions of the real proof and the fake, simulated one (would be an entire transcript of messages in the interactive setting). In this vein, it is important to note that the simulator $\mathcal{S}$, who has the ``trapdoor'' value $\tau$ used to generate the preprocessing, \textit{does not know a valid witness}. If one cannot tell these proofs apart in polynomial time, then this corresponds to the proof not leaking any information that would allow doing so using witness information. ``Statistical'' zero-knowledge implies that even a computationally unbounded entity cannot distinguish the real and fake proofs except with small probability. Though the statistical properties are stronger, the computational variants enable the integration of cryptographic primitives to form SNARKs, which in turn enable small proofs and fast verification in real blockchain systems. But the statistical properties form a necessary theoretical cornerstone.

\subsection{Early work}
\noindent SNARKs are preceded by foundational work in complexity theory, probabilistic proofs, and cryptography. First was the formalization of interactive proofs by Goldwasser et al.\ \cite{ipfirst}, which established a theoretical framework by which a prover $\mathcal{P}$ exchanges a finite number of messages during \textit{interaction} with a verifier $\mathcal{V}$, which issues \textit{random challenges} to $\mathcal{P}$ in order to verify their claim. They also introduced the notion of zero-knowledge via which a proof system leaks no other information beyond the validity of the claim being verified. Arora et al. \cite{pcpthm1, pcpthm2} later drew the seminal equivalence between NP and PCP$[O(\log n), O(1)]$, yielding a powerful characterization of NP as the set of languages with PCP verifiers needing logarithmic randomness bits and \textit{constant queries}, where $n$ is the statement size. Given results showing all NP languages can have \textit{very} efficient verifiers, the following question naturally arises: do ``short enough'' or \textit{succinct} arguments of knowledge exist for NP? Kilian's construction \cite{kilian} realized such a thing using merkle tree commitments to probabilistically checkable proofs (PCPs), and Micali later showed how to make his argument non-interactive \cite{micalisnark} using the aforementioned Fiat-Shamir heuristic \cite{fiatshamir}. Despite these breakthroughs, SNARKs constructed from PCPs were undesirable due to massive overhead incurred in proof construction. Many approaches instead use algebraic characterizations of NP which admit means to efficient polynomial equality/divisibility testing. Additionally integrating ``compiled'' interaction and suitable cryptographic commitment schemes brings us closer to the practical SNARK schemes used in real-world blockchain systems.\\

\noindent As seen in Kilian's work, along this path to practically succinct argument systems lies an interesting avenue: considering only computationally bounded adversaries. In doing so, one can now use cryptographic schemes to produce small encrypt proof elements and quickly verify their integrity, while ensuring the intractability of breaking soundness. Pairing-based cryptography, which allows one to check algebraic relationships between quantities ``in the exponent'' using bilinear functions (behaving like multiplication) on elliptic curve group elements, spurred a sequence of works leading to methods practical enough for real-world blockchain applications. Though faster, all of these methods require stronger security assumptions. In particular, pairing-based methods derive their security in part from the elliptic curve discrete log assumption, which is stronger than the collision resistance assumptions used in other hashing-based methods \cite{starks, ligero, hyrax, aurora}. Within and across denominations of SNARKs, such tradeoffs between performance, security, and flexibility are recurring points of comparison; and where they appear becomes clearer with a picture of which components are stitched together to form a SNARK.


\section{Preliminaries}
\subsection{A general ``workflow'' for SNARKs}
\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        node distance=0.8cm,
        box/.style={rectangle, draw, rounded corners, minimum width=1.4cm, minimum height=0.6cm, text width=1.3cm, align=center, font=\tiny},
        box-highlight/.style={rectangle, draw=red!70, line width=1pt, rounded corners, minimum width=1.4cm, minimum height=0.6cm, text width=1.3cm, align=center, font=\tiny},
        arrow/.style={->, >=latex, font=\tiny},
        arrow-highlight/.style={->, >=latex, draw=red!70, line width=1pt, font=\tiny}
    ]

    % Define nodes - first column
    \node[box-highlight] (comp) {computation};

    % Second column
    \node[box-highlight] (circ) [right=0.7cm of comp] {circuit};
    \node[box] (aet) [below=0.5cm of circ] {AET};

    % Third column
    \node[box-highlight] (r1cs) [right=0.7cm of circ] {R1CS};
    \node[box-highlight] (cust) [below=0.5cm of r1cs] {custom NP repr.};
    \node[box] (air) [below=0.5cm of cust] {AIR};

    % Fourth column
    \node[box-highlight] (polyid) [right=0.7cm of r1cs] {PEQ};
    \node[box] (cw) [below=1cm of polyid] {PCW};

    % Fifth column
    \node[box-highlight] (crypto) [right=0.7cm of polyid] {pairing-based CC};
    \node[box] (crypto2) [below=1cm of crypto] {hashing-based CC};

    % Sixth column
    \node[box-highlight] (pair) [right=0.7cm of crypto] {PC};
    \node[box] (prox) [below=1cm of pair] {PPT};

    % Define connections
    \draw[arrow-highlight] (comp) -- (circ);
    \draw[arrow] (comp) to[bend right=20] (aet);

    \draw[arrow-highlight] (circ) -- (r1cs);
    \draw[arrow-highlight] (circ) -- (cust);
    \draw[arrow] (aet) -- (air);

    \draw[arrow-highlight] (r1cs) -- (polyid);
    \draw[arrow-highlight] (cust) -- (polyid);
    \draw[arrow] (air) -- (cw);
    \draw[arrow] (cust) to[bend right=15] (cw);
    \draw[arrow] (r1cs) to[bend right=30] (cw);

    \draw[arrow-highlight] (polyid) -- (crypto);
    \draw[arrow] (cw) -- (crypto2);

    \draw[arrow-highlight] (crypto) -- (pair);
    \draw[arrow] (crypto2) -- (prox);

    \end{tikzpicture}
    \caption{A general workflow describing how SNARKs reduce checking computation to checking polynomials. The highlighted path shows the course pairing-based approaches take. Acronyms: AET = algebraic execution trace, AIR = algebraic intermediate representation, CC = cryptographic compilation, PCW = polynomial codeword, PEQ = polynomial equality, PC = pairing check, PPT = polynomial proximity testing, R1CS = rank-1 constraint system.}
    \label{fig:snark-workflow}
\end{figure}
\noindent Modern SNARKs largely use the "workflow" depicted in figure \ref{fig:snark-workflow} to prove/verify computation. Here there are two courses; one reduces to checking polynomial relationships using pairing-based cryptography (left), and the other reduces to checking proximity to a Reed-Solomon code via combination of coding theoretic results and merkle trees. In an interactive setting, the "checks" or "testing" steps might involve randomized interaction with the verifier; but many interactive-proof-based methods use Fiat-Shamir to have the prover simulate such interaction, which the verifier can check. To balance coverage, depth, and accessibility, this paper focuses on approaches involving pairing-based cryptography (highlighted paths). We leave the surveying of methods using hashing-based cryptography as future work.

\subsection{Representing the complexity class NP}
\noindent Crucial to modern SNARKs is their representation of NP. How the computation to verify is ``framed'' directly influences how synergistic each method is with algebraic objects like polynomials and the cryptographic methods applied to them. This in turn affects the proof size and prover/verifier complexity, all of which are highly relevant to blockchain infrastructure/applications using SNARKs. Clearly, one must use an NP-complete language compatible with other aspects of the method in question. The most immediate choice of representation is boolean circuit satisfiability; in light of the use of polynomials, a reasonable sequel is \textit{arithmetic} circuit satisfiability, in which the circuit of importance uses addition gates in place of OR gates, and multiplication gates in place of AND gates. Wires can also take on values in some prime field $F_p$  rather than just 0 or 1. A natural question arises: are there representations of NP that seamlessly connect arithmetic circuit satisfiability with polynomial equality testing? The answer is yes, and we discuss notable examples of this below.

\subsubsection{Rank 1 Constraint System (R1CS)}
Let $m, n \in \mathbb{N}$, and consider an arithmetic circuit with $m$ gates and $n$ input variables. with A rank-1 constraint system (R1CS) consists of a vector $w \in \mathbb{F}_{p}^{n}$, the matrices $L, R, O \in \mathbb{F}_{p}^{m \times n}$ and the relationship
\begin{align}
Ow = (Lw) \circ (Rw)
\end{align}
A rank-1 constraint system (R1CS) \textit{arithmetizes} the relationships between the left inputs, right inputs, and outputs of each gate, respectively. It assumes that the circuit has been preprocessed so that only multiplication gates remain, with the addition gates instead expressed as sums input to the multiplication gates. Intuitively, row $i$ of $L$ can be seen as a ``selector'' for the values in $w$ that, when linearly combined via row $L_i$, form the left input to gate $i$. The same logic applies for $R$ and $O$. Applying this logic in aggregate yields the above relationship between a Hadamard product of vectors and the desired output vector - in other words, three rank-1 matrices (hence ``rank-1''). This problem is NP-complete with a relatively simple reduction from arithmetic circuit-SAT (follows easily from the loose definition above). One can also view it as a consolidation of the equations in the constraint system used by Bootle et al. \cite{bootlezkargs}, which uses two separate equations for multiplication gate constraints and linear constraints.

\subsubsection{Quadratic Arithmetic Program (QAP)}
Connecting the R1CS representation of NP with polynomials involves converting either the rows or the columns of $L, R, O$ into polynomials and creating some relationship that holds if and only if $Ow = (Lw) \circ (Rw)$. Given that for the $i$-th gate we have
\begin{align}
(Oz)_i = \left(\sum_{j=1}^n L_{ij}w_j\right)\left(\sum_{j=1}^n R_{ij}w_j\right)
\end{align}
It could make sense to create a polynomial for the $j$-th witness variable which evaluate to each $L_{ij}$ given the gate $i$. This would involve interpolating column $j$ of the matrix $L$ into a polynomial $u_j(x)$. The same intuition applies to the matrices $R, O$ (using $v_j(x), w_j(x)$ respectively) and is the idea behind the quadratic arithmetic program (QAP) introduced by Gennaro et al. \cite{snarknopcp}. We focus on the definition of a regular QAP.

\begin{definition}[regular QAP]
A regular Quadratic Arithmetic Program $Q$ over a field $\mathbb{F}_p$ comprises:
\begin{itemize}
    \item The target polynomial $t(x) = \prod_{i=1}^m (x - i)$, where $m$ is the number of gates
    \item The polynomials $\{u_i(x), v_i(x), w_i(x)\}_{i=0}^n$, where $u_i(j) = L_{ji}$, $v_i(j) = R_{ji}$, and $w_i(j) = O_{ji}$
\end{itemize}

$Q$ is satisfied by a witness $c \in \mathbb{F}_p^n$ if and only if:
\begin{align}
p(x) = \left(\sum_{i=0}^n c_i u_i(x)\right) \cdot \left(\sum_{i=0}^n c_i v_i(x)\right) - \left(\sum_{i=0}^n c_i w_i(x)\right) = h(x)t(x) \equiv 0 \mod t(x)
\end{align}
\end{definition}

\noindent Here $t(x) | p(x)$ is synonymous with $p(x)$ vanishing at all points which are gate identifiers, which will be true if the gate relationship is indeed satisfied by the given inputs, and will not be true otherwise. QAP satisfiability is NP-complete, as can be shown via reduction from R1CS-SAT or arithmetic circuit-SAT.\\

\noindent Though not exhaustive by any means, these two representations of NP yield a connection between the computation being verified, arithmetic circuit satisfiability, and an instance of polynomial divisibility testing. From this point, the polynomial divisibility check can be verified in a hidden fashion using pairing-based cryptography. This idea is used by virtually all pairing-based methods, with modifications to the constraint system and the polynomial relationship being checked.

\subsection{Polynomial Distinguishability}
\noindent As mentioned, modern SNARKs reduce proving/verifying statements about computation to polynomial identity/property testing via suitable characterizations of NP. The use of polynomials over other mathematical objects is justified by how little information one needs to distinguish between two polynomials, which is a consequence of the following lemma.

\begin{lemma}{Schwarz-Zippel lemma}
\noindent Let $f(x_1, x_2, \dots x_n) \in R[x_1 \dots x_n]$ be a nonzero polynomial in $n$ variables defined over an integral domain $\mathbb{F}^{n}$. Suppose the element $(a_1, a_2, \dots a_n)$ is selected uniformly at random from a finite subset $S \subset \mathbb{F}^n$. Then 
$$
    \Pr(f(a_1, a_2, \dots a_n) = 0) \le \frac{\text{deg}(f)}{|S|}
$$
\end{lemma}

\noindent where $\text{deg}(f)$ is the maximum sum of the degrees of any term's variables. It immediately follows that if $f = g-h$, then for a randomly sampled point $(a_1, \dots a_n) \in \mathbb{F}$, we have that $\Pr(g(a_1, \dots a_n) = h(a_1, \dots a_n))$ is bounded from above by $\frac{d}{|\mathbb{F}|}$. In other words, $g$ and $h$ will output different values at $(a_1 \dots a_n)$ with high probability if they are not equal, assuming the $d$ and $\mathbb{F}$ are chosen so that $d \ll |\mathbb{F}|$. Thus, given the right choice of degree and field size, a verifier will still be able to distinguish between two unequal polynomials with high probability using a single evaluation point. Succinct argument systems can make use of this to check polynomial equalities at a single point with small proof size, fast verification, and little probability of spurious equality.

\subsection{Pairing-based Cryptography}

\noindent Pairing-based cryptography \cite{ibepairings} allows one to check algebraic relationships between quantities ``in the exponent'' using bilinear functions on arbitrary source group elements (usually from elliptic curve groups). This technique works well with checking polynomial equalities and is frequently used in modern SNARKs as a result. Elliptic curve groups are preferred here due to small key sizes, which are determined by the size of the base field the point coordinates are from. There is also a group operation over elliptic curve points behaving like addition, in which one computes a sum of points $A + B$ by reflecting over the $x$-axis the point on both the curve and the line $AB$ (if $A = B$ we use the tangent line through $A$). We can then define multiplication of a point $A$ by some $s \in \mathbb{F}_s$ in the curve's \textit{scalar field} as summing $s$ copies of $A$. Here, $s$ can be considered an \textit{elliptic curve discrete logarithm} and is believed to be hard to compute given $A$ and $sA$; this is the elliptic curve variant of the discrete log assumption. The hardness of this problem yields a scheme for additively homomorphic encryption: given a cyclic multiplicative group $\mathbb{G}$ over some wisely-chosen elliptic curve and its generator $G$, encrypt $x$ as $xG \in \mathbb{G}$. Pairings can render this scheme \textit{doubly} homomorphic due to the properties of bilinear pairings, which behave like multiplication (linear in each input). This paper abstracts elliptic curve groups and pairings for brevity; we instead focus on the properties they exhibit which make pairing-based cryptography useful in this setting.\\

\noindent More formally, suppose we have two cyclic elliptic curve groups $\mathbb{G}_1$ and $\mathbb{G}_2$ generated by elements $G_1$ and $G_2$, respectively. We denote the scalar multiple of a point $P \in \mathbb{G}_i$ by $kP$, which is just the same as $k$ additions of $P$ and $k \in \mathbb{F}_s$ where $\mathbb{F}_s$ is some scalar field. For a bilinear pairing $e: \mathbb{G}_1 \times \mathbb{G}_2 \to \mathbb{G}_t$ where $P_1 \in \mathbb{G}_1$ and $P_2 \in \mathbb{G}_2$, we have the following properties:
\begin{itemize}
    \item for $a, b \in \mathbb{F}$, $e(aP_1, bP_2) e(P_1, P_2)^{ab} = e(P_1, P_2)^{ba} = e(bP_1, aP_2)$
    \item for $Q_1 \in \mathbb{G}_1$, $e(P_1+Q_1, P_2) = e(P_1, P_2) e(Q_1, P_2)$
    \item for $Q_2 \in \mathbb{G}_2$, $e(P_1, P_2+Q_2) = e(P_1, P_2) e(P_1, Q_2)$
    \item $e(G_1, G_2)$ generates $\mathbb{G}_t$ (non-degeneracy)
\end{itemize}

These properties make it easy to check multiplicative relationships. For instance, suppose we have three polynomials $A(x), B(x), C(x)$ and we want to check that $A(\alpha)B(\alpha) = C(\alpha)$ for some input $\alpha$. From bilinearity of $e$ it follows that 
\begin{align*}
e(G_1, G_2)^{A(\alpha)B(\alpha)} &= e(G_1, G_2)^{C(\alpha)} \\
\Leftrightarrow e([A(\alpha)]_1, [B(\alpha)]_2) &= e([C(\alpha)]_1, G_2)
\end{align*}
where $[A(\alpha)]_1 = A(\alpha)G_1$ (same idea for the other values). So if we can reduce checking circuit satisfiability to checking a polynomial relationship, we can send elliptic curve points as proof elements with which the verifier would perform such a pairing check. The complexity of a naive pairing computation is quasi-quadratic in the target group size, but there are pairing-friendly choices of elliptic curve groups which make this operation faster. 

\subsection{Polynomial commitment schemes (PCS)}
\noindent A polynomial commitment scheme is a protocol by which a prover claims they know a polynomial $f(x)$ satisfying some relationship, and a verifier checks this claim. A noteworthy example of such a relationship is that $f(y) = z$ for some fixed $y, z$. We detail a noteworthy polynomial commitment scheme for this exact task known as the Kate-Zaverucha-Goldberg commitment scheme (KZG) \cite{kzg}. Suppose $P$ wants to prove they know $f$ of degree $d$ such that $f(\beta) = z$. It follows that $f(X) - z$ is divisible by $(X - \beta)$, so we should be able to construct $h(X) = \frac{f(X) - z}{X - \beta}$ since we know $f$. $P$ commits to $f$ and $h$ by their hidden evaluations on some $\alpha$ agreed upon in advance by the $P$ and the verifier $V$. In practice, the evaluations are hidden via scalar multiplication by an elliptic curve group generator $g_1 \in \mathbb{G}_1$. This scheme uses two elliptic curve groups for this purpose, so assume the point $g_2$ generates the EC group $\mathbb{G}_2$. Let $[a]_i = ag_i \in \mathbb{G}_i$. Suppose $\mathcal{P}$ and $\mathcal{V}$ agree on a \textit{trusted setup} containing the hidden terms $\{[1]_1, [\alpha]_1, [\alpha^2]_1, \dots [\alpha^{d}]_1, [1]_2, [\alpha]_2\}$. $P$ sends $[f(\alpha)]_1$ and $[h(\alpha)]_2$. $V$ then sends a challenge point $\gamma$ to which $\mathcal{P}$ responds with $[f(\gamma)]_1$ and $[h(\gamma)]_1$. $V$ then checks that $f(\gamma) - z = h(\gamma)(\gamma - \alpha)$ where $h$ was constructed from the evaluation requirement we wanted to prove that $f$ satisfies. For a bilinear pairing function $e : \mathbb{G}_1 \times \mathbb{G}_2 \to \mathbb{G}_t$, $\mathcal{V}$ checks that 
\begin{align}
&e([f(\gamma) - z]_1, g_2) = e([h(\gamma)]_1, [\gamma]_2 - [\alpha]_2) \\
&\Leftrightarrow e(g_1, g_2)^{f(\gamma) - z} = e(g_1, g_2)^{h(\gamma)(\gamma - \alpha)} \\
&\Leftrightarrow  f(\gamma) - z = h(\gamma)(\gamma - \alpha)
\end{align}

\noindent KZG commitment schemes require constant size communication since the polynomials involved can be collapsed to a point without losing virtually any distinguishability. Given their use of elliptic curve groups to meet this end, their security depends on the hardness of computing elliptic curve discrete logarithms (find $\alpha$ given the points $g$ and $\alpha g$), for which no classical polynomial time algorithm is known \cite{ecdlp}. The drawbacks of using this scheme include the need to generate a trusted setup and the lack of post-quantum security. Being quite customizable, KZG works with batching, multivariate polynomials, and various optimizations for faster polynomial operations. That said, many methods use different polynomial commitment schemes, some of which avoid pairing-based cryptography entirely. Nonetheless we opt for this example to give an idea of commitment schemes making use of pairings, as this is relevant to many modern pairing-based SNARKs.
