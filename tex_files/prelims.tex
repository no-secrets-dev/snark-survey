\section{Preliminaries}

\subsection{What is a SNARK?}
\noindent Loosely speaking, a succinct non-interactive argument of knowledge is a short, one-shot proof that one $knows$ some ``witness'' or value $w$ satisfying a claim $C$ related to public input(s) $x$. In practice, $C$ is a claim that $x \in L$, where $L \in \text{NP}$. We give a more formal definition below.\\

\subsubsection{A more formal definition}
\noindent Let the relation $\mathcal{R} = \{(x, w)\} \subseteq \{0, 1\}^{*} \times \{0, 1\}^{*}$ be decidable in deterministic polynomial time, where $|w| = \mathsf{poly}(|x|)\ \forall (x, w) \in \mathcal{R}$. Let $\lambda \in \mathbb{N}$ denote a security parameter. Define the language $L = \{x\ |\ \exists w\ \text{s.t.}\ (x, w) \in \mathcal{R}\}$. A succinct non-interactive argument of knowledge is the tuple of PPT algorithms $(\sf{Setup}, \sf{Prove}, \sf{Verify})$ where:
\begin{itemize}
    \item $\sf{Setup}(1^{\lambda}, \mathcal{R}) \rightarrow \sigma$ receives an input security parameter and relation, and outputs a common reference string (CRS) $\sigma$ containing the ``setup'' terms the prover and verifier will use to construct/verify proofs
    \item $\sf{Prove}(\sigma, x, w) \rightarrow \pi$ receives the CRS, string $x$, and witness $w$ and outputs a proof $\pi$
    \item $\sf{Verify}(\sigma, x, \pi) \rightarrow \{0, 1\}$ receives the CRS, string $x$, and proof $\pi$; it outputs 1 (accepts) or 0 (rejects)
\end{itemize}

\noindent and $\sf{Setup}, \sf{Prove}, \sf{Verify}$ have the following properties:
\begin{itemize}
    \item \textbf{completeness:} If $\pi \leftarrow \sf{Prove}(\sigma, x, w)$ and $(x, w) \in \mathcal{R}$ then $\sf{Verify}$ outputs 1 
    \item \textbf{soundness:} For all possible PPT algorithms $\sf{Prove'}$, if $\pi' \leftarrow \sf{Prove'}(\sigma, x, w)$ and $x \notin L$, then $\sf{Verify}(\sigma, x, \pi') = 1$ with probability at most $\delta_s$ ($\mathcal{V}$ rejects with probability at least $1 - \delta_s$). 
    \item \textbf{knowledge soundness:} For all possible PPT algorithms $\sf{Prove'}$, if $\pi' \leftarrow \sf{Prove'}(\sigma, x)$ and $\sf{Verify}(\sigma, x, \pi') = 1$ with non-negligible probability, then there exists a PPT extractor $\mathcal{E}$ which, given access to the same inputs as $\sf{Prove}$ and $\mathcal{P}$'s random tape, outputs $w$ s.t. $(x, w) \in \mathcal{R}$. 
    \item \textbf{succinctness:} Let $(x, w) \in \mathcal{R}$ and $\pi \leftarrow \sf{Prove}(\sigma, x, w)$. $|\pi|$ is polylogarithmic in $|x|$, prover complexity is quasilinear in $|x|$, and verifier complexity is polylogarithmic in $|x|$. Setup complexity is quasilinear in $|x|$. 
    \item \textbf{non-interactivity:} $\pi$ is generated without any interaction between $\mathcal{P}$ and $\mathcal{V}$ after setup.
\end{itemize}

\noindent As an example, $L$ could be the set of string encodings of satisfiable boolean circuits (there's some input out there making the circuit output `True`. The claim to be proven is that $x \in L$, where $x$ is the encoding of the circuit in question; since $L$ is fixed here, the claim can just be represented by $x$. Our witness $w$ is our potentially secret ``certificate'' proving the validity of the claim.\\

\subsection{Early work}
\noindent Succinct non-interactive arguments of knowledge are preceded by foundational work in complexity theory, probabilistic proofs, and cryptography. First and foremost was the formalization of interactive proofs by Goldwasser et al.\ \cite{ipfirst}, which established a theoretical framework by which a prover $\mathcal{P}$ exchanges a finite number of messages during \textit{interaction} with a verifier $\mathcal{V}$, which issues \textit{random challenges} to $\mathcal{P}$ in order to verify their claim. They also introduced the notion of zero-knowledge.\\ 

\noindent An obvious choice of proof system would involve sending the full ``certificate'' of the given problem's solution to $\mathcal{V}$; however, this is not succinct or zero-knowledge. In light of this, the following question seems natural: do ``short enough'' or \textit{succinct} arguments of knowledge exist for NP? Kilian's construction \cite{kilian} found an affirmative answer to this inquiry (for verification at least) using merkle tree commitments to probabilistically checkable proofs (PCPs), and Micali later showed how to make this argument non-interactive \cite{micalisnark} using the Fiat-Shamir heuristic \cite{fiatshamir}. Despite these breakthroughs, SNARKs constructed from PCPs were undesirable due to massive overhead incurred in proof construction. Many approaches which address this fundamental issue use alternate characterizations of NP -- namely rank-1 constraint systems (R1CS), and algebraic intermediate representations (AIRs) -- which admit means to efficient polynomial identity/property testing. Additionally integrating ``compiled'' interaction and suitable cryptographic commitment schemes can reduce prover complexity, proof length, and verifier complexity.\\

\noindent As seen in Kilian's work, along this path to succinctness lies an interesting and practically necessary avenue: considering only computationally bounded adversaries. In doing so, one can now use cryptographic schemes to encrypt proof elements and verify their integrity. This can enable small proof sizes and fast verification while still making it infeasible to break soundness in polynomial time. Pairing-based cryptography, which allows one to check algebraic relationships between quantities ``in the exponent'' using bilinear functions (behaving like multiplication) on elliptic curve group elements, spurred a sequence of works leading to methods practical enough for real-world blockchain applications. Though faster, all of these methods require stronger assumptions about what information an adversary must know to have produced a particular group element. Due to the use of elliptic curve cryptography (ECC), they also derive their security from the discrete log assumption, which is stronger than the collision resistance assumptions used in other hashing-based methods like STARKs. With the pairing-based denomination of SNARKs and others, the tradeoff between performance and security is a recurring and noteworthy point of comparison.


\subsection{A general ``workflow'' for SNARKs}
Modern SNARKs largely use the "workflow" depicted below to prove/verify computation:
\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[
        node distance=1.5cm,
        box/.style={rectangle, draw, rounded corners, minimum width=2cm, minimum height=0.8cm, text width=1.9cm, align=center, font=\footnotesize},
        box-highlight/.style={rectangle, draw=red!70, line width=1.2pt, rounded corners, minimum width=2cm, minimum height=0.8cm, text width=1.9cm, align=center, font=\footnotesize},
        arrow/.style={->, >=latex},
        arrow-highlight/.style={->, >=latex, draw=red!70, line width=1.2pt}
    ]
    
    % Define nodes - first row
    \node[box-highlight] (comp) {computation};
    
    % Second row
    \node[box-highlight] (circ) [below left=0.8cm and 0.3cm of comp] {circuit};
    \node[box] (aet) [below right=0.8cm and 0.3cm of comp] {AET};
    
    % Third row
    \node[box-highlight] (r1cs) [below left=0.8cm and 0cm of circ] {R1CS};
    \node[box-highlight] (cust) [below right=0.8cm and 0cm of circ] {custom NP repr.};
    \node[box] (air) [below=0.8cm of aet] {AIR};
    
    % Fourth row
    \node[box-highlight] (polyid) [below right=0.8cm and 0.3cm of r1cs] {poly. EQ};
    \node[box] (cw) [below right=0.8cm and 0.3cm of air] {poly. CW};
    
    % Fifth row
    \node[box-highlight] (crypto) [below=0.8cm of polyid] {pairing-based CC};
    \node[box] (crypto2) [below=0.8cm of cw] {hashing-based CC};
    
    % Sixth row
    \node[box-highlight] (pair) [below=0.8cm of crypto] {PC};
    \node[box] (prox) [below=0.8cm of crypto2] {PPT};
    
    % Define connections - with highlighting for the pairing-based path
    \draw[arrow-highlight] (comp) -- (circ);
    \draw[arrow] (comp) -- (aet);
    
    \draw[arrow-highlight] (circ) -- (r1cs);
    \draw[arrow-highlight] (circ) -- (cust);
    \draw[arrow] (aet) -- (air);
    
    \draw[arrow-highlight] (r1cs) -- (polyid);
    \draw[arrow-highlight] (cust) -- (polyid);
    \draw[arrow] (air) -- (cw);
    \draw[arrow] (cust) -- (cw);
    \draw[arrow] (r1cs) -- (cw);
    
    \draw[arrow-highlight] (polyid) -- (crypto);
    \draw[arrow] (cw) -- (crypto2);
    
    \draw[arrow-highlight] (crypto) -- (pair);
    \draw[arrow] (crypto2) -- (prox);
    
    \end{tikzpicture}
    \caption{A general workflow describing how SNARKs convert computations into verifiable statements. The highlighted path shows the course pairing-based approaches take. Acronyms: AET = algebraic execution trace, AIR = algebraic intermediate representation, CC = cryptographic compilation, CW = codewordx, EQ = polynomial equality, PC = pairing check, PPT = polynomial proximity testing, R1CS = rank-1 constraint system.}
    \label{fig:snark-workflow}
\end{figure}
\noindent Here there are two courses; one reduces to checking polynomial relationships using pairing-based cryptography (left), and the other reduces to checking proximity to a Reed-Solomon code via combination of coding theoretic results and merkle trees. In an interactive setting, the "checks" or "testing" steps might involve randomized interaction with the verifier; but many methods use Fiat-Shamir to have the prover simulate such interaction, which the verifier can check. The result is an interactive protocol compiled into a succinct non-interactive argument of knowledge (the "compilation" here is different from the compilation mentioned in the graph above). To balance coverage, depth, and accessibility, this paper focuses on approaches involving pairing-based cryptography (highlighted paths). We leave the surveying of methods using hashing-based cryptography as future work.

\subsection{Representing the complexity class NP}
\noindent Crucial to modern SNARKs is their representation of NP. How the computation to verify is ``framed'' directly influences how synergistic each method is with algebraic objects like polynomials and the cryptographic methods applied to them. Clearly, one must use an NP-complete language compatible with other aspects of the method in question. The most immediate choice of representation is boolean circuit satisfiability; in light of the use of polynomials, a reasonable sequel is \textit{arithmetic} circuit satisfiability, in which the circuit of importance uses addition gates in place of OR gates, and multiplication gates in place of AND gates. Wires can also take on values in some prime field $F_p$  rather than just 0 or 1. A natural question arises: are there representations of NP that seamlessly connect arithmetic circuit satisfiability with polynomial testing? The answer is yes, and we discuss notable examples of this below.

\subsubsection{Rank 1 Constraint System (R1CS)}
Let $m, n \in \mathbb{N}$, and consider an arithmetic circuit with $m$ gates and $n$ input variables. with A rank-1 constraint system [5] (R1CS) consists of a vector $w \in \mathbb{F}_{p}^{n}$, the matrices $L, R, O \in \mathbb{F}_{p}^{m \times n}$ and the relationship
\begin{align}
Ow = (Lw) \circ (Rw)
\end{align}
A rank-1 constraint system (R1CS) \textit{arithmetizes} the relationships between the left inputs, right inputs, and outputs of each gate, respectively. It assumes that the circuit has been preprocessed so that only multiplication gates remain, with the addition gates instead expressed as sums input to the multiplication gates. Intuitively, row $i$ of $L$ can be seen as a ``selector'' for the values in $w$ that, when linearly combined via row $L_i$, form the left input to gate $i$. The same logic applies for $R$ and $O$. Applying this logic in aggregate yields the above relationship between a Hadamard product of vectors and the desired output vector - in other words, three rank-1 matrices (hence ``rank-1''). This problem is NP-complete with a relatively simple reduction from arithmetic circuit-SAT (follows easily from the loose definition above). One can also view it as a consolidation of the equations in the constraint system used by Bootle et al.[5], which uses two separate equations for multiplication gate constraints and linear constraints.

\subsubsection{Quadratic Arithmetic Program (QAP)}
Connecting the R1CS representation of NP with polynomials involves converting either the rows or the columns of $L, R, O$ into polynomials and creating some relationship that holds if and only if $Ow = (Lw) \circ (Rw)$. Given that for the $i$-th gate we have
\begin{align}
(Oz)_i = \left(\sum_{j=1}^n L_{ij}w_j\right)\left(\sum_{j=1}^n R_{ij}w_j\right)
\end{align}
It could make sense to create a polynomial for each of the $n$ witness variables which evaluate to each $L_{ij}$ given the gate $i$. This would involve interpolating column $j$ of the matrix $L$ into a polynomial $u_j(x)$. The same intuition applies to the matrices $R, O$ (using $v_j(x), w_j(x)$ respectively) and is the idea behind the quadratic arithmetic program (QAP) introduced by Gennaro et al. \cite{snarknopcp}. We focus on the definition of a regular QAP.

\begin{definition}[regular QAP]
A regular Quadratic Arithmetic Program $Q$ over a field $\mathbb{F}_p$ comprises:
\begin{itemize}
    \item The target polynomial $t(x) = \prod_{i=1}^m (x - i)$, where $m$ is the number of gates
    \item Three sets of polynomials $\{u_i(x)\}_{i=0}^n$, $\{v_i(x)\}_{i=0}^n$, and $\{w_i(x)\}_{i=0}^n$, where $u_i(j) = L_{ji}$, $v_i(j) = R_{ji}$, and $w_i(j) = O_{ji}$
\end{itemize}

$Q$ is satisfied by a witness $c \in \mathbb{F}_p^n$ if and only if:
\begin{align}
p(x) = \left(\sum_{i=0}^n c_i u_i(x)\right) \cdot \left(\sum_{i=0}^n c_i v_i(x)\right) - \left(\sum_{i=0}^n c_i w_i(x)\right) = h(x)t(x) \equiv 0 \mod t(x)
\end{align}
\end{definition}

\noindent Here $t(x) | p(x)$ is synonymous with $p(x)$ vanishing at all points which are gate identifiers, which will be true if the gate relationship is indeed satisfied by the given inputs, and will not be true otherwise. QAP satisfiability is also NP-complete with intuitive reductions from arithmetic circuit-SAT and R1CS. Gennaro et al. originally coined QAPs as a way to compute arithmetic circuits, but the relationship to R1CS is more noteworthy given the methods to be discussed, hence the slightly altered presentation.\\

\noindent Though not exhaustive by any means, these two representations of NP yield a connection between the computation being verified, arithmetic circuit satisfiability, and an instance of polynomial divisibility testing. From this point, the polynomial divisibility check can be verified in a hidden fashion using pairing-based cryptography. This idea is used by virtually all pairing-based methods, with modifications to the constraint system and the polynomial relationship being checked.

\subsection{Polynomial Properties}
\noindent As mentioned, modern SNARKs reduce proving/verifying statements about computation to polynomial identity/property testing via suitable characterizations of NP. A natural question about this arises: why polynomials over other mathematical objects? The answer lies in how little information one needs to distinguish between two arbitrary polynomials, which is a consequence of the following lemma.

\subsubsection{Schwarz-Zippel lemma}
\noindent Let $f(x_1, x_2, \dots x_n) \in R[x_1 \dots x_n]$ be a nonzero polynomial in $n$ variables defined over an integral domain $\mathbb{F}^{n}$. Suppose the element $(a_1, a_2, \dots a_n)$ is selected uniformly at random from a finite subset $S \subset \mathbb{F}^n$. Then 
$\Pr(f(a_1, a_2, \dots a_n) = 0) \le \frac{\text{deg}(f)}{|S|}$
where $\text{deg}(f)$ is the maximum sum of the degrees of any term's variables. It immediately follows that if $f = g-h$, as $g$ and $h$ are distinct since $f$ is not zero; then for a randomly sampled point $(a_1, \dots a_n)$, the probability that 
$(g-h)(a_1, \dots a_n) = 0 \Leftrightarrow g(a_1, \dots a_n) = h(a_1, \dots a_n)$
is identically bounded. In other words, $g$ and $h$ will output different values at $(a_1 \dots a_n)$ with high probability if they are not equal, assuming the $d$ and $\mathbb{F}$ are chosen appropriately $d \ll |F|$. Thus, given the right choice of degree and field size, a verifier will still be able to distinguish between two unequal polynomials with high probability using a single evaluation point.\\ 

\noindent Schemes relying on this property would yield shorter proofs, since we need a single evaluation point; faster prover complexity, since polynomial evaluation has many known efficient algorithms over both finite fields and the real numbers; and faster verification, since checking a polynomial identity can be done quickly via point evaluation without significant soundness loss. Thus, if a succinct argument system can verify identities resemblent to this one, it would warrant the characterization of the claim being proven in a manner easily convertible to a collection/combination of polynomials.

\subsection{Pairing-Friendly Elliptic Curve Cryptography}

\noindent Pairing-based cryptography, which allows one to check algebraic relationships between quantities ``in the exponent'' using bilinear functions on arbitrary source group elements (usually from elliptic curve groups), is a heavily used cryptographic primitive in modern SNARKs. Elliptic curve groups are preferred here due to small key sizes -- determined by the size of the base field the coordinates of the points from. There is also a natural group operation over elliptic curve points behaving like addition; when compounded with the hardness of computing discrete logarithms over elliptic curve groups, this yields a scheme for additively homomorphic encryption. Pairings can render this scheme \textit{doubly} homomorphic due to the properties of bilinear pairings. This paper abstracts the details of elliptic curve groups for brevity; we instead focus on the properties they exhibit which make them a useful component of pairing-based cryptography.\\

\noindent More formally, suppose we have two cyclic elliptic curve groups $\mathbb{G}_1$ and $\mathbb{G}_2$ generated by elements $G_1$ and $G_2$, respectively. We denote the scalar multiple of a point $P \in \mathbb{G_1}$ by $kP$, which is just the same as $k$ additions of $P$ and $k \in \mathbb{F}_s$ where $\mathbb{F}_s$ is some scalar field. For a bilinear pairing $e: \mathbb{G}_1 \times \mathbb{G}_2 \to \mathbb{G}_t$ where $P_1 \in \mathbb{G}_1$ and $P_2 \in \mathbb{G}_2$, we have the following properties:
\begin{itemize}
    \item for $s \in \mathbb{F}$, $e(P_1, sP_2) = e(sP_1, P_2) = e(P_1, P_2)^s$
    \item for $Q_1 \in \mathbb{G}_1$, $e(P_1+Q_1, P_2) = e(P_1, P_2) e(Q_1, P_2)$
    \item for $Q_2 \in \mathbb{G}_2$, $e(P_1, P_2+Q_2) = e(P_1, P_2) e(P_1, Q_2)$
    \item $e(G_1, G_2)$ generates $\mathbb{G}_t$ (non-degeneracy)
\end{itemize}

These properties make it easy to check multiplicative relationships. For instance, suppose we have three polynomials $A(x), B(x), C(x)$ and we want to check that $A(\alpha)B(\alpha) = C(\alpha)$ for some input $\alpha$. From bilinearity of $e$ It follows that 
\begin{align}
e(G_1, G_2)^{A(\alpha)B(\alpha)} &= e(G_1, G_2)^{C(\alpha)} \\
\Leftrightarrow e([A(\alpha)]_1, [B(\alpha)]_2) &= e([C(\alpha)]_1, G_2)
\end{align}
where $[A(\alpha)]_1 = A(\alpha)G_1$ (same idea for the other values). So if we can reduce checking circuit satisfiability to checking a polynomial relationship, we can send elliptic curve points as proof elements with which the verifier would perform such a pairing check. The complexity of a naive pairing computation is quasi-quadratic in the target group size, but there are pairing-friendly choices of elliptic curve groups which make this operation faster. Most importantly, the number of pairings to be performed does not depend on the size of the computation being verified.

\subsection{Polynomial commitment scheme (PCS)}

\noindent A polynomial commitment scheme is a protocol by which a prover claims they know a polynomial $f(x)$ satisfying some relationship, and a verifier checks this claim. A noteworthy example of such a relationship is that $f(y) = z$ for some fixed $y, z$. We detail a noteworthy polynomial commitment scheme for this exact task known as the KZG commitment scheme, named after the authors Kate et al. Kate-Zaverucha-Goldberg (KZG) commitments facilitate verification of the commitment made by a prover $P$ to a specific polynomial $f$ meeting certain requirements [7]. Suppose $P$ wants to prove they know $f$ of degree $d$ such that $f(\beta) = z$. It follows that $f(X) - z$ is divisible by $(X - \beta)$, so we should be able to construct
\begin{align}
h(X) = \frac{f(X) - z}{X - \beta}
\end{align}
since we know $f$. $P$ commits to $f$ and $h$ by their hidden evaluations on some $\alpha$ agreed upon in advance by the $P$ and the verifier $V$. In practice, the evaluations are hidden via scalar multiplication by an elliptic curve group generator $g_1 \in \mathbb{G}_1$. This scheme uses two elliptic curve groups for this purpose, so assume the point $g_2$ generates the EC group $\mathbb{G}_2$. Let $[a]_i = ag_i \in \mathbb{G}_i$. Suppose $\mathcal{P}$ and $\mathcal{V}$ agree on a \textit{trusted setup} containing the hidden terms 
\begin{align}
\{[1]_1, [\alpha]_1, [\alpha^2]_1, \dots [\alpha^{d}]_1, [1]_2, [\alpha]_2\}
\end{align}

$P$ sends $[f(\alpha)]_1$ and $[h(\alpha)]_2$. $V$ then sends a challenge point $\gamma$ to which $\mathcal{P}$ responds with $[f(\gamma)]_1$ and $[h(\gamma)]_1$. $V$ then checks that $f(\gamma) - z = h(\gamma)(\gamma - \alpha)$ where $h$ was constructed from the evaluation requirement we wanted to prove that $f$ satisfies. For a bilinear pairing function $e : \mathbb{G}_1 \times \mathbb{G}_2 \to \mathbb{G}_t$, $\mathcal{V}$ checks that 
\begin{align}
&e([f(\gamma) - z]_1, g_2) = e([h(\gamma)]_1, [\gamma]_2 - [\alpha]_2) \\
&\Leftrightarrow e(g_1, g_2)^{f(\gamma) - z} = e(g_1, g_2)^{h(\gamma)(\gamma - \alpha)} \\
&\Leftrightarrow  f(\gamma) - z = h(\gamma)(\gamma - \alpha)
\end{align}

\noindent KZG commitment schemes require constant size communication since the polynomials involved can be collapsed to a point without losing virtually any distinguishability. Given their use of elliptic curve points to meet this end, their security depends on the hardness of computing elliptic curve discrete logarithms (find $\alpha$ given the points $g$ and $\alpha g$), for which no classical polynomial time algorithm is known \cite{ecdlp}. The drawbacks of using this scheme include the need to generate a trusted setup upstream, and the reliance on the discrete log assumption (not post-quantum).\\

\noindent There are other general and protocol-specific commitment schemes which check slightly different polynomial relationships than KZG or avoid pairing-based cryptography entirely. But we opt for this example to give an idea of commitment schemes making use of pairings, as this is relevant to every modern pairing-based SNARK discussed.

\subsection{Turning interactive protocols non-interactive}
\noindent nothing.
